{% set cov_enabled = (cov_enabled == "1") %}
{% set docker_image = "public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT" %}
{% set pull_through_docker_image = "936637512419.dkr.ecr.us-west-2.amazonaws.com/vllm-ci-pull-through-cache/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT" %}
{% set docker_image_torch_nightly = "public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT-torch-nightly" %}
{% set docker_image_cpu = "public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT-cpu" %}
{% set docker_image_arm64_cpu = "public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$BUILDKITE_COMMIT-arm64-cpu" %}
{% if branch == "main" %}
{% set docker_image = "public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:$BUILDKITE_COMMIT" %}
{% set pull_through_docker_image = "936637512419.dkr.ecr.us-west-2.amazonaws.com/vllm-ci-pull-through-cache/q9t5s3a7/vllm-ci-postmerge-repo:$BUILDKITE_COMMIT" %}
{% set docker_image_latest = "public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:latest" %}
{% set docker_image_torch_nightly = "public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:$BUILDKITE_COMMIT-torch-nightly" %}
{% set docker_image_cpu = "public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:$BUILDKITE_COMMIT-cpu" %}
{% set docker_image_arm64_cpu = "public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:$BUILDKITE_COMMIT-arm64-cpu" %}
{% set docker_image_hpu = "public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:$BUILDKITE_COMMIT-hpu" %}
{% endif %}
{% set docker_image_amd = "rocm/vllm-ci:$BUILDKITE_COMMIT" %}
{% set default_working_dir = "/vllm-workspace/tests" %}
{% set hf_home = "/root/.cache/huggingface" %}
{% set hf_home_efs = "/mnt/efs/hf_cache" %}
{% set hf_home_fsx = "/fsx/hf_cache" %}
{% set list_file_diff = list_file_diff | split("|") %}

{% macro add_pytest_coverage(cmd, coverage_file) %}
{% if "pytest " in cmd %}
COVERAGE_FILE={{ coverage_file }} {{ cmd | replace("pytest ", "pytest --cov=vllm --cov-report= --cov-append --durations=0 ") }} || true
{% else %}
{{ cmd }}
{% endif %}
{% endmacro %}

{% macro add_docker_pytest_coverage(step, cov_enabled) %}
{# Compute coverage file id #}
{% set step_length = step.label | length %}
{% set step_first = step.label | first | default("x") %}
{% set coverage_file = ".coverage." + step_length ~ "_" ~ step_first %}

{% if cov_enabled %}
{% set ns = namespace(has_pytest=false) %}
{% if step.command %}
{% if "pytest " in step.command %}{% set ns.has_pytest = true %}{% endif %}
{{ add_pytest_coverage(step.command, coverage_file) }}
{% else %}
{% for cmd in step.commands %}
{% if "pytest " in cmd %}{% set ns.has_pytest = true %}{% endif %}
{{ add_pytest_coverage(cmd, coverage_file) }}{{ " && " if not loop.last else "" }}{% endfor %}
{% endif %}{% if ns.has_pytest %} && curl -sSL https://raw.githubusercontent.com/vllm-project/ci-infra/{{ vllm_ci_branch | default('main') }}/buildkite/scripts/upload_codecov.sh | bash -s -- \"{{ step.label }}\"{% endif %}
{% else %}
{{ step.command or (step.commands | join(' && ')) | safe }}
{% endif %}
{% endmacro %}

{% macro render_cuda_config(step, image, default_working_dir, hf_home_fsx, hf_home, branch) %}
agents:
  {% if step.label == "Documentation Build" %}
  queue: small_cpu_queue_premerge
  {% elif step.no_gpu %}
  queue: cpu_queue_premerge_us_east_1
  {% elif step.gpu == "a100" %}
  queue: a100_queue
  {% elif step.gpu == "h100" %}
  queue: mithril-h100-pool
  {% elif step.gpu == "h200" %}
  queue: skylab-h200
  {% elif step.gpu == "b200" %}
  queue: B200
  {% elif step.num_gpus == 2 or step.num_gpus == 4 %}
  queue: gpu_4_queue
  {% else %}
  queue: gpu_1_queue
  {% endif %}

{% if step.num_nodes >= 2 %}
commands:
  - ./.buildkite/scripts/run-multi-node-test.sh {{ (step.working_dir or default_working_dir) | safe }} {{ step.num_nodes }} {{ step.num_gpus }} {{ image }} {% for command in step.commands %}"{{ (command | join(' && ')) | safe }}" {% endfor %}
{% endif %}

{% if step.parallelism %}
parallelism: {{ step.parallelism }}
{% endif %}

retry:
  automatic:
    - exit_status: -1
      limit: 1
    - exit_status: -10
      limit: 1

{% if step.num_nodes < 2 %}
plugins:
  {% if step.gpu != "a100" and step.gpu != "h100" and step.gpu != "h200" and step.gpu != "b200" %}
  - docker#v5.2.0:
      image: {{ image }}
      always-pull: true
      propagate-environment: true
      {% if not step.no_gpu %}
      gpus: all
      {% endif %}
      {% if step.label == "Benchmarks" or step.mount_buildkite_agent or cov_enabled %}
      mount-buildkite-agent: true
      {% endif %}
      command: ["bash", "{% if fail_fast == "true" %}-xce{% else %}-xc{% endif %}", "(command nvidia-smi || true) && export CUDA_ENABLE_COREDUMP_ON_EXCEPTION=1 && export CUDA_COREDUMP_SHOW_PROGRESS=1 && export CUDA_COREDUMP_GENERATION_FLAGS='skip_nonrelocated_elf_images,skip_global_memory,skip_shared_memory,skip_local_memory,skip_constbank_memory' && cd {{ (step.working_dir or default_working_dir) | safe }} && {{ add_docker_pytest_coverage(step, cov_enabled) }}"]
      environment:
        - VLLM_USAGE_SOURCE=ci-test
        - NCCL_CUMEM_HOST_ENABLE=0
        - HF_HOME={{ hf_home_fsx }}
        - HF_TOKEN
        - CODECOV_TOKEN
        {% if fail_fast == "true" %}
        - PYTEST_ADDOPTS=-x
        {% endif %}
        {% if branch == "main" %}
        - BUILDKITE_ANALYTICS_TOKEN
        {% endif %}
        {% if step.label == "Speculative decoding tests" %}
        - VLLM_ATTENTION_BACKEND=XFORMERS
        {% endif %}
      volumes:
        - /dev/shm:/dev/shm
        - {{ hf_home_fsx }}:{{ hf_home_fsx }}
  {% elif step.gpu == "h200" %}
   - docker#v5.2.0:
      image: {{ image }}
      always-pull: true
      propagate-environment: true
      gpus: all
      command: ["bash", "{% if fail_fast == "true" %}-xce{% else %}-xc{% endif %}", "(command nvidia-smi || true) && export VLLM_ALLOW_DEPRECATED_BEAM_SEARCH=1 && cd {{ (step.working_dir or default_working_dir) | safe }} && {{ add_docker_pytest_coverage(step, cov_enabled) }}"]
      environment:
        - VLLM_USAGE_SOURCE=ci-test
        - NCCL_CUMEM_HOST_ENABLE=0
        - HF_HOME=/benchmark-hf-cache
        - HF_TOKEN
        - CODECOV_TOKEN
        {% if step.num_gpus and step.num_gpus == 2 %}
        - CUDA_VISIBLE_DEVICES=1,2
        {% endif %}
        {% if fail_fast == "true" %}
        - PYTEST_ADDOPTS=-x
        {% endif %}
        {% if branch == "main" %}
        - BUILDKITE_ANALYTICS_TOKEN
        {% endif %}
      volumes:
        - /dev/shm:/dev/shm
        - /data/benchmark-hf-cache:/benchmark-hf-cache
        - /data/benchmark-vllm-cache:/root/.cache/vllm
  {% elif step.gpu == "b200" %}
   - docker#v5.2.0:
      image: {{ image }}
      always-pull: true
      propagate-environment: true
      # gpus will be configured by BUILDKITE_PLUGIN_DOCKER_GPUS in per host environment variable.
      # gpus: all
      command: ["bash", "{% if fail_fast == "true" %}-xce{% else %}-xc{% endif %}", "(command nvidia-smi || true) && export VLLM_ALLOW_DEPRECATED_BEAM_SEARCH=1 && cd {{ (step.working_dir or default_working_dir) | safe }} && {{ add_docker_pytest_coverage(step, cov_enabled) }}"]
      environment:
        - VLLM_USAGE_SOURCE=ci-test
        - NCCL_CUMEM_HOST_ENABLE=0
        - HF_HOME=/benchmark-hf-cache
        - HF_TOKEN
        - CODECOV_TOKEN
        {% if fail_fast == "true" %}
        - PYTEST_ADDOPTS=-x
        {% endif %}
        {% if branch == "main" %}
        - BUILDKITE_ANALYTICS_TOKEN
        {% endif %}
      volumes:
        - /dev/shm:/dev/shm
        - /data/benchmark-hf-cache:/benchmark-hf-cache
        - /data/benchmark-vllm-cache:/root/.cache/vllm
  {% elif step.gpu == "h100" %}
  - kubernetes:
      podSpec:
        containers:
          - image: {{ image }}
            command:
              - bash -c "{{ '(command nvidia-smi || true) && export VLLM_ALLOW_DEPRECATED_BEAM_SEARCH=1 && cd ' ~ ((step.working_dir or default_working_dir) | safe) ~ ' && ' ~ (step.command or (step.commands | join(" && ")) | safe) }}"
            resources:
              limits:
                nvidia.com/gpu: {{ step.num_gpus or 1 }}
            volumeMounts:
              - name: devshm
                mountPath: /dev/shm
              - name: hf-cache
                mountPath: {{ hf_home }}
            env:
              - name: VLLM_USAGE_SOURCE
                value: ci-test
              - name: NCCL_CUMEM_HOST_ENABLE
                value: "0"
              - name: HF_HOME
                value: {{ hf_home }}
              - name: HF_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: hf-token-secret
                    key: token
        nodeSelector:
          node.kubernetes.io/instance-type: gpu-h100-sxm
        volumes:
          - name: devshm
            emptyDir:
              medium: Memory
          - name: hf-cache
            hostPath:
              path: /mnt/hf-cache
              type: DirectoryOrCreate
  {% else %}
  - kubernetes:
      podSpec:
        priorityClassName: ci
        containers:
          - image: {{ image }}
            command:
              - bash -c "{{ '(command nvidia-smi || true) && export VLLM_ALLOW_DEPRECATED_BEAM_SEARCH=1 && cd ' ~ ((step.working_dir or default_working_dir) | safe) ~ ' && ' ~ (step.command or (step.commands | join(" && ")) | safe) }}"
            resources:
              limits:
                nvidia.com/gpu: {{ step.num_gpus or 1 }}
            volumeMounts:
              - name: devshm
                mountPath: /dev/shm
              - name: hf-cache
                mountPath: {{ hf_home }}
            env:
              - name: VLLM_USAGE_SOURCE
                value: ci-test
              - name: NCCL_CUMEM_HOST_ENABLE
                value: "0"
              - name: HF_HOME
                value: {{ hf_home }}
              - name: HF_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: hf-token-secret
                    key: token
        nodeSelector:
          nvidia.com/gpu.product: NVIDIA-A100-SXM4-80GB
        volumes:
          - name: devshm
            emptyDir:
              medium: Memory
          - name: hf-cache
            hostPath:
              path: {{ hf_home }}
              type: Directory
  {% endif %}
{% endif %}
{% endmacro %}


steps:
  - label: ":docker: build image (with prebake simulation)"
    key: image-build
    depends_on: ~
    timeout_in_minutes: 600
    agents:
      {% if branch == "main" %}
      queue: cpu_queue_postmerge_us_east_1
      {% else %}
      queue: cpu_queue_premerge_us_east_1
      {% endif %}
    commands:
      - "aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/q9t5s3a7"
      - "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 936637512419.dkr.ecr.us-east-1.amazonaws.com"
      - |
        #!/bin/bash
        set -e

        # Check if current commit image already exists
        echo "--- :mag: Checking if current commit image exists"
        START_TIME=$$(date +%s)
        if docker manifest inspect {{ docker_image }} > /dev/null 2>&1; then
          echo "Image already exists, skipping build"
          exit 0
        fi
        END_TIME=$$(date +%s)
        echo "✓ Image check completed in $$((END_TIME - START_TIME)) seconds"

        # Find and pull parent commit image (simulating prebaked image)
        echo "--- :arrow_down: Pulling parent commit image (prebake simulation)"
        START_TIME=$$(date +%s)
        PARENT_COMMIT=$$(git rev-parse HEAD^)
        echo "Parent commit: $$PARENT_COMMIT"

        PARENT_IMAGE_TEST="public.ecr.aws/q9t5s3a7/vllm-ci-test-repo:$$PARENT_COMMIT"
        PARENT_IMAGE_POSTMERGE="public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:$$PARENT_COMMIT"
        PARENT_IMAGE=""

        echo "Checking for parent image in test-repo..."
        if docker manifest inspect "$$PARENT_IMAGE_TEST" > /dev/null 2>&1; then
          echo "Found parent image in test-repo"
          PARENT_IMAGE="$$PARENT_IMAGE_TEST"
        elif docker manifest inspect "$$PARENT_IMAGE_POSTMERGE" > /dev/null 2>&1; then
          echo "Found parent image in postmerge-repo"
          PARENT_IMAGE="$$PARENT_IMAGE_POSTMERGE"
        else
          echo "Parent image not found in either registry"
        fi

        if [ -n "$$PARENT_IMAGE" ]; then
          echo "Pulling parent image: $$PARENT_IMAGE"
          docker pull "$$PARENT_IMAGE" || echo "Failed to pull parent image"
        fi
        END_TIME=$$(date +%s)
        echo "✓ Parent image pull completed in $$((END_TIME - START_TIME)) seconds"

        # Setup buildx
        echo "--- :hammer: Setting up buildx"
        START_TIME=$$(date +%s)
        docker buildx create --name vllm-builder --driver docker-container --use
        docker buildx inspect --bootstrap
        docker buildx ls
        END_TIME=$$(date +%s)
        echo "✓ Buildx setup completed in $$((END_TIME - START_TIME)) seconds"

        # Build with timing
        echo "--- :docker: Building Docker image"
        BUILD_START=$$(date +%s)

        docker buildx build --file docker/Dockerfile \
        --build-arg max_jobs=16 \
        --build-arg buildkite_commit=$$BUILDKITE_COMMIT \
        --build-arg USE_SCCACHE=1 \
        --build-arg TORCH_CUDA_ARCH_LIST="8.0 8.9 9.0 10.0" \
        --build-arg FI_TORCH_CUDA_ARCH_LIST="8.0 8.9 9.0a 10.0a" \
        --build-arg VLLM_USE_PRECOMPILED={{ vllm_use_precompiled | default("0") }} \
        {% if vllm_use_precompiled == "1" %}
        --build-arg VLLM_MERGE_BASE_COMMIT={{ vllm_merge_base_commit }} \
        {% endif %}
        --cache-to type=registry,ref={{ cache_to }},mode=max,compression=zstd \
        --cache-from type=registry,ref={{ cache_from }},mode=max \
        --cache-from type=registry,ref={{ cache_from_base_branch }},mode=max \
        --cache-from type=registry,ref={{ cache_from_main }},mode=max \
        --cache-from type=registry,ref="$$PARENT_IMAGE_TEST",mode=max \
        --cache-from type=registry,ref="$$PARENT_IMAGE_POSTMERGE",mode=max \
        --tag {{ docker_image }} \
        {% if branch == "main" %}
        --tag {{ docker_image_latest }} \
        {% endif %}
        --push \
        --target test \
        --progress plain .

        BUILD_END=$$(date +%s)
        BUILD_DURATION=$$((BUILD_END - BUILD_START))
        echo ""
        echo "=========================================="
        echo "✓ Docker build completed in $$BUILD_DURATION seconds ($$(echo "scale=2; $$BUILD_DURATION/60" | bc) minutes)"
        echo "=========================================="
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 2
        - exit_status: -10  # Agent was lost
          limit: 2

